{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/riiid_comp\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(os.getcwd())\n",
    "code_path = './'\n",
    "sys.path.append(code_path)\n",
    "sys.path.append(code_path + 'script')\n",
    "\n",
    "train_pickle = './cv1_train.pickle'\n",
    "valid_pickle = './cv1_valid.pickle'\n",
    "question_file = './questions.csv'\n",
    "debug = False\n",
    "validaten_flg = False\n",
    "\n",
    "train = pd.read_pickle(train_pickle)\n",
    "valid = pd.read_pickle(valid_pickle)\n",
    "\n",
    "train = train.loc[train.content_type_id == 0].reset_index(drop=True)\n",
    "valid = valid.loc[valid.content_type_id == 0].reset_index(drop=True)\n",
    "# valid = valid.sort_values(['timestamp'])\n",
    "\n",
    "questions = pd.read_csv('./questions.csv')\n",
    "map_dict = questions.set_index(['question_id'])['correct_answer'].to_dict()\n",
    "train['correct_answer'] = train['content_id'].map(map_dict)\n",
    "valid['correct_answer'] = valid['content_id'].map(map_dict)\n",
    "\n",
    "\n",
    "sample_size = 4 * 1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_user function took 25.310 s\n",
      "initial_dict function took 6.870 s\n",
      "initial_item function took 6.250 s\n",
      "valid_user function took 2.620 s\n",
      "initial_item function took 0.230 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12534"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from user_feature import initial_user\n",
    "from state_feature import initial_attempt,dict_trans\n",
    "from state_feature import dict_trans\n",
    "from item_feature import initial_item\n",
    "from utils import initial_dict\n",
    "from user_feature import valid_user\n",
    "from state_feature import state_feature\n",
    "from item_feature import initial_item\n",
    "\n",
    "\n",
    "\n",
    "ds1 = initial_user(train)\n",
    "# ds2, state_dict = initial_attempt(train)\n",
    "# state_dict = dict_trans(state_dict)\n",
    "user_dict, item_dict = initial_dict(train)\n",
    "ds3 = initial_item(train, item_dict)\n",
    "\n",
    "# del ds1, ds2, ds3;gc.collect()\n",
    "\n",
    "valid_ds1 = valid_user(valid, user_dict)\n",
    "# valid_ds2, state_dict = state_feature(valid, state_dict)\n",
    "valid_ds3 = initial_item(valid, item_dict)\n",
    "\n",
    "del user_dict, item_dict;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n",
    "train['prior_question_elapsed_time'] = train.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "train['prior_question_had_explanation'] = train.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "\n",
    "X = train.iloc[-int(sample_size):]\n",
    "\n",
    "X[ds1.columns] = ds1.iloc[-int(sample_size):]\n",
    "# X[ds2.columns] = ds2.iloc[-int(sample_size):]\n",
    "X[ds3.columns] = ds3.iloc[-int(sample_size):]\n",
    "\n",
    "\n",
    "add_feature = []\n",
    "add_feature.extend(list(ds1.columns))\n",
    "# add_feature.extend(list(ds2.columns))\n",
    "add_feature.extend(list(ds3.columns))\n",
    "del ds1, ds3;gc.collect()\n",
    "# del ds1, ds2, ds3;gc.collect()\n",
    "# , ds6\n",
    "# del train;gc.collect()\n",
    "\n",
    "valid[valid_ds1.columns] = valid_ds1\n",
    "# valid[valid_ds2.columns] = valid_ds2\n",
    "valid[valid_ds3.columns] = valid_ds3\n",
    "\n",
    "valid['prior_question_elapsed_time'] = valid.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "valid['prior_question_had_explanation'] = valid.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "\n",
    "del valid_ds1, valid_ds3, ;gc.collect()\n",
    "# valid_ds6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_dict_init_ function took 4.990 s\n",
      "content_encoder1 function took 27.180 s\n",
      "content_encoder2 function took 10.760 s\n",
      "read_enc_data function took 0.070 s\n",
      "content_emb_dict_init_ function took 43.000 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19703"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from content_encoding import content_emb_dict_init_, initial_embedding_feature\n",
    "\n",
    "content_emb_dict,content_emb_cols = content_emb_dict_init_(train)\n",
    "content_emb_ds = initial_embedding_feature(X, content_emb_dict)\n",
    "valid_content_emb_ds = initial_embedding_feature(valid, content_emb_dict)\n",
    "\n",
    "X[content_emb_cols] = pd.DataFrame(content_emb_ds, index = X.index)\n",
    "valid[content_emb_cols] = pd.DataFrame(valid_content_emb_ds, index = valid.index)\n",
    "add_feature.extend(content_emb_cols)\n",
    "\n",
    "del content_emb_dict;\n",
    "del content_emb_ds, valid_content_emb_ds;\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/177764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat5_group function took 45.030 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177764/177764 [00:30<00:00, 5901.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat5_group function took 1.830 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feat_group5 import  feats5_wrap, roll_init, valid_feats5_wrap\n",
    "\n",
    "group5, ds5, col_name = feats5_wrap(X)\n",
    "roll_group = roll_init(group5, 50)\n",
    "valid_ds5 = valid_feats5_wrap(valid, roll_group)\n",
    "\n",
    "X[col_name] = pd.DataFrame(ds5, index=X.index)\n",
    "valid[col_name] = pd.DataFrame(valid_ds5, index=valid.index)\n",
    "add_feature.extend(col_name)\n",
    "\n",
    "del group5;gc.collect()\n",
    "del ds5,valid_ds5;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/177764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_feat_group function took 49.290 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177764/177764 [00:32<00:00, 5514.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel_wrap function took 35.460 s\n",
      "rolling_feat_group function took 2.530 s\n",
      "valid_rolling_feature function took 9.600 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rolling_feature import rolling_feat_group, valid_rolling_feature, roll_init, parallel_wrap, resort_array\n",
    "\n",
    "def resort_array(test_ds, idx):\n",
    "    new_test = np.zeros(test_ds.shape)\n",
    "    for i in range(idx.shape[0]):\n",
    "        new_test[idx[i]] = test_ds[i]\n",
    "    return new_test\n",
    "\n",
    "def rolling_feature_wrapper(X, roll_keep):\n",
    "    shift_period_1 = [1, 5, 10, 20, 30, 40]\n",
    "    group, roll_idx, name_dict = rolling_feat_group(X, roll_keep)\n",
    "    roll_ds = parallel_wrap(group, name_dict, shift_period_1)\n",
    "    roll_ds = resort_array(roll_ds, roll_idx)\n",
    "    \n",
    "    rolling_name = []\n",
    "    func_list = ['mean']\n",
    "    rolling_name += [f'container_{func}_{p}' for p in shift_period_1 for func in ['mean', 'std']]\n",
    "\n",
    "    rolling_name += [f'prior_question_elapsed_time_{func}_{p}' for p in shift_period_1 for func in func_list]\n",
    "    rolling_name += [f'item_mean_{func}_{p}' for p in shift_period_1 for func in func_list]\n",
    "    rolling_name += [f'task_set_distance_{func}_{p}' for p in shift_period_1 for func in func_list]\n",
    "    \n",
    "\n",
    "    return group, name_dict, roll_ds, rolling_name\n",
    "\n",
    "def valid_rolling_feature_wrapper(valid, group):\n",
    "    shift_period_1 = [1, 5, 10, 20, 30, 40]\n",
    "    roll_mean_group = roll_init(group, 300)\n",
    "    valid_gp, valid_idx, name_dict = rolling_feat_group(valid, roll_keep)\n",
    "#     valid_gp, valid_shape_list = pre_merge_group(valid_gp, roll_mean_group)\n",
    "#     valid_roll_ds = valid_parallel_rolling_wrap(valid_gp, valid_shape_list, name_dict, valid_idx, shift_period_1)\n",
    "    valid_roll_ds = valid_rolling_feature(valid_gp, roll_mean_group, name_dict, shift_period_1)\n",
    "    valid_roll_ds = resort_array(valid_roll_ds, valid_idx)\n",
    "    return valid_roll_ds\n",
    "\n",
    "\n",
    "roll_keep = ['user_id', 'timestamp', 'content_id', 'answered_correctly',\n",
    "             'prior_question_elapsed_time', 'item_mean', 'task_set_distance', 'part', 'bundle_id']\n",
    "# shift_period_1 = [1, 5, 10, 20, 30, 40]\n",
    "group, name_dict, roll_ds, rolling_name = rolling_feature_wrapper(X, roll_keep)\n",
    "valid_roll_ds = valid_rolling_feature_wrapper(valid, group)\n",
    "X[rolling_name] = pd.DataFrame(roll_ds, index=X.index)\n",
    "valid[rolling_name] = pd.DataFrame(valid_roll_ds, index=valid.index)\n",
    "add_feature.extend(rolling_name)\n",
    "\n",
    "del group;gc.collect()\n",
    "del roll_ds,valid_roll_ds;gc.collect()\n",
    "\n",
    "# # for col in rolling_name:\n",
    "# #     if col in add_feature:\n",
    "# #         add_feature.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from numba import jit,njit\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from multiprocessing import Process, Manager,Pool\n",
    "from functools import partial\n",
    "from numba import prange\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import types\n",
    "from numba.typed import Dict\n",
    "import functools, time\n",
    "\n",
    "from multiprocessing import Process, Manager,Pool\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def timeit(f):\n",
    "    def wrap(*args, **kwargs):\n",
    "        time1 = time.time()\n",
    "        ret = f(*args, **kwargs)\n",
    "        time2 = time.time()\n",
    "        print('{:s} function took {:.3f} s'.format(f.__name__, np.round(time2-time1, 2)))\n",
    "\n",
    "        return ret\n",
    "    return wrap\n",
    "\n",
    "@timeit\n",
    "def rolling_feat_group(train, col_used):\n",
    "    a = train[col_used].values\n",
    "    ind = np.lexsort((a[:,2],a[:,1],a[:,0]))\n",
    "    a = a[ind]\n",
    "    g = np.split(a, np.unique(a[:, 0], return_index=True)[1][1:])\n",
    "    return g, ind, col_used\n",
    "\n",
    "def resort_array(test_ds, idx):\n",
    "    new_test = np.zeros(test_ds.shape)\n",
    "    for i in range(idx.shape[0]):\n",
    "        new_test[idx[i]] = test_ds[i]\n",
    "    return new_test\n",
    "\n",
    "@jit(nopython = True)\n",
    "def divide_agg(tmp_g, step, name_dict):\n",
    "\n",
    "\n",
    "    beg = 0\n",
    "    \n",
    "    time_idx = name_dict.index('timestamp')\n",
    "    answer_idx = name_dict.index('answered_correctly')\n",
    "    item_mean_idx = name_dict.index('item_mean')\n",
    "    distance_idx = name_dict.index('task_set_distance')\n",
    "    content_idx = name_dict.index('content_id')\n",
    "    prior_idx = name_dict.index('prior_question_elapsed_time')\n",
    "    bundle_idx = name_dict.index('bundle_id')\n",
    "    \n",
    "    \n",
    "    m = 2\n",
    "    ret1 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret2 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret3 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret4 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret5 = np.zeros((tmp_g.shape[0], 2))\n",
    "    ret6 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret7 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret8 = np.zeros((tmp_g.shape[0], 4))\n",
    "    \n",
    "    ret9 = np.zeros((tmp_g.shape[0], 2))\n",
    "    ret10 = np.zeros((tmp_g.shape[0], 5))\n",
    "    \n",
    "    ret11 = np.zeros((tmp_g.shape[0], 6))\n",
    "    \n",
    "    \n",
    "    bundle_ret1 = np.zeros((tmp_g.shape[0], m))\n",
    "    bundle_ret2 = np.zeros((tmp_g.shape[0], m))\n",
    "    bundle_ret3 = np.zeros((tmp_g.shape[0], m))\n",
    "    bundle_ret4 = np.zeros((tmp_g.shape[0], 3))\n",
    "    \n",
    "#     real_time = prior_shift_func(tmp_g[:, time_idx], tmp_g[:, prior_idx])\n",
    "#     exp_idx = name_dict.index('prior_question_had_explanation')\n",
    "#     exp_ret1 = np.zeros((tmp_g.shape[0], 3))\n",
    "    \n",
    "    for i in step:\n",
    "        tmp = tmp_g[:beg]\n",
    "        idx1 = np.where(tmp[:,  answer_idx] == 0)[0]\n",
    "        if idx1.shape[0] > 0:\n",
    "#             wrong_time_diff = shift_inner_func(tmp[idx1, time_idx])\n",
    "            wrong_time_diff = tmp[idx1, time_idx] - np.concatenate((np.full(1, np.nan), tmp[idx1, time_idx][:-1]))\n",
    "            \n",
    "            ret1[beg:beg+i, 0] = np.nanmean(tmp[idx1, item_mean_idx])\n",
    "            ret1[beg:beg+i, 1] = np.nanmedian(tmp[idx1, item_mean_idx])\n",
    "        \n",
    "            ret2[beg:beg+i, 0] = np.nanmean(tmp[idx1, distance_idx])\n",
    "            ret2[beg:beg+i, 1] = np.nanmedian(tmp[idx1, distance_idx])\n",
    "            \n",
    "            ret5[beg:beg+i, 0] = tmp_g[beg][time_idx] - tmp[idx1][-1, time_idx]\n",
    "            ret6[beg:beg+i, 0] = np.nanmean(wrong_time_diff)\n",
    "            ret6[beg:beg+i, 1] = np.nanmedian(wrong_time_diff)\n",
    "            \n",
    "\n",
    "            \n",
    "            hard_item = np.where(tmp[idx1, item_mean_idx] < 0.6)[0]\n",
    "            if hard_item.shape[0] > 0:\n",
    "                hard_time = tmp[idx1,:][hard_item, time_idx]\n",
    "                ret9[beg:beg+i, 0] = tmp_g[beg, time_idx] - hard_time[-1]\n",
    "            \n",
    "        idx2 = np.where(tmp[:, answer_idx] == 1)[0]\n",
    "        if idx2.shape[0] > 0:\n",
    "#             right_time_diff = shift_inner_func(tmp[idx2, time_idx])\n",
    "            right_time_diff = tmp[idx2, time_idx] - np.concatenate((np.full(1, np.nan), tmp[idx2, time_idx][:-1]))\n",
    "            ret3[beg:beg+i, 0] = np.nanmean(tmp[idx2, item_mean_idx])\n",
    "            ret3[beg:beg+i, 1] = np.nanmedian(tmp[idx2, item_mean_idx])\n",
    "            \n",
    "            ret4[beg:beg+i, 0] = np.nanmean(tmp[idx2, distance_idx])\n",
    "            ret4[beg:beg+i, 1] = np.nanmedian(tmp[idx2, distance_idx])\n",
    "            \n",
    "            ret5[beg:beg+i, 1] = tmp_g[beg][time_idx] - tmp[idx2][-1, time_idx]\n",
    "        \n",
    "            ret7[beg:beg+i, 0] = np.nanmean(right_time_diff)\n",
    "            ret7[beg:beg+i, 1] = np.nanmedian(right_time_diff)\n",
    "            \n",
    "            \n",
    "            hard_item = np.where(tmp[idx2, item_mean_idx] < 0.6)[0]\n",
    "            if hard_item.shape[0] > 0:\n",
    "                hard_time = tmp[idx2, :][hard_item, time_idx]\n",
    "                ret9[beg:beg+i, 1] = tmp_g[beg, time_idx] - hard_time[-1]\n",
    "               \n",
    "        for j in range(i):\n",
    "            last_idx = np.where(tmp[:, content_idx] == tmp_g[beg+j, content_idx])[0]\n",
    "            if last_idx.shape[0] > 0:\n",
    "                last_content_time = tmp[last_idx[-1], time_idx]\n",
    "                ret8[beg+j, 1] = np.nanmean(tmp[last_idx, answer_idx])\n",
    "                ret8[beg+j, 2] = np.nansum(tmp[last_idx, answer_idx])\n",
    "                ret8[beg+j, 3] = tmp[last_idx, answer_idx].shape[0]\n",
    "            else:\n",
    "                last_content_time = np.nan\n",
    "            ret8[beg+j, 0] = tmp_g[beg+j, time_idx] - last_content_time\n",
    "            \n",
    "        ret11[beg:beg+i, 0] = ret2[beg:beg+i, 1]/(1e-6 + ret4[beg:beg+i, 1])\n",
    "        ret11[beg:beg+i, 1] = ret1[beg:beg+i, 1]/(1e-6 + ret3[beg:beg+i, 1])\n",
    "        ret11[beg:beg+i, 2] = ret6[beg:beg+i, 1]/(1e-6 + ret7[beg:beg+i, 1])\n",
    "\n",
    "        ret11[beg:beg+i, 3] = ret5[beg:beg+i, 0]/(1e-6 + ret6[beg:beg+i, 1])\n",
    "        ret11[beg:beg+i, 4] = ret5[beg:beg+i, 0]/(1e-6 + ret5[beg:beg+i, 1])\n",
    "        ret11[beg:beg+i, 5] = ret5[beg:beg+i, 1]/(1e-6 + ret7[beg:beg+i, 1])\n",
    "        \n",
    "\n",
    "            \n",
    "        for shift in range(1, 6):\n",
    "            if tmp.shape[0] > shift:\n",
    "                ret10[beg:beg+i, shift - 1] = tmp[-shift, distance_idx]\n",
    "        \n",
    "        selected_bundle = tmp_g[beg, bundle_idx]\n",
    "        group_idx = np.where(tmp[:, bundle_idx] == selected_bundle)[0]\n",
    "        if group_idx.shape[0] > 0:\n",
    "            part_diff_time = tmp[group_idx, time_idx] - np.concatenate((np.full(1, np.nan), tmp[group_idx, time_idx][:-1]))\n",
    "            bundle_ret1[beg:beg+i, 0] = np.nanmean(tmp[group_idx, item_mean_idx])\n",
    "            bundle_ret1[beg:beg+i, 1] = np.nanmedian(tmp[group_idx,  item_mean_idx])\n",
    "            bundle_ret2[beg:beg+i, 0] = np.nanmean(tmp[group_idx, distance_idx])\n",
    "            bundle_ret2[beg:beg+i, 1] = np.nanmedian(tmp[group_idx, distance_idx])\n",
    "            bundle_ret3[beg:beg+i, 0] = np.nanmean(part_diff_time)\n",
    "            bundle_ret3[beg:beg+i, 1] = np.nanmedian(part_diff_time)\n",
    "        \n",
    "            bundle_ret4[beg:beg+i, 0] = np.nansum(tmp[group_idx, answer_idx])\n",
    "            bundle_ret4[beg:beg+i, 1] = tmp[group_idx, answer_idx].shape[0]\n",
    "            bundle_ret4[beg:beg+i, 2] = np.nanmean(tmp[group_idx, answer_idx])\n",
    "            \n",
    "#         selected_exp = tmp_g[beg, exp_idx]\n",
    "#         group_idx = np.where(tmp[:, exp_idx] == selected_exp)[0]\n",
    "#         if group_idx.shape[0] > 0:\n",
    "        \n",
    "#             exp_ret1[beg:beg+i, 0] = np.nansum(tmp[group_idx, answer_idx])\n",
    "#             exp_ret1[beg:beg+i, 1] = tmp[group_idx, answer_idx].shape[0]\n",
    "#             exp_ret1[beg:beg+i, 2] = np.nanmean(tmp[group_idx, answer_idx])\n",
    "            \n",
    "        beg += i\n",
    "    \n",
    "    bundle_ret = np.concatenate((bundle_ret1, bundle_ret2, bundle_ret3, bundle_ret4), axis = 1)\n",
    "    ret = np.concatenate((ret1, ret2, ret3, ret4, ret5, ret6, ret7, ret8, ret9, \n",
    "                          ret10, bundle_ret, ret11), axis = 1)\n",
    "    return ret\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "@jit(nopython = True)\n",
    "def last_group_cal(tmp_g, step, name_dict):\n",
    "    beg = 0\n",
    "    part_group = np.zeros((tmp_g.shape[0], 9))\n",
    "    \n",
    "    part_idx = name_dict.index('part')\n",
    "    time_idx = name_dict.index('timestamp')\n",
    "    answer_idx = name_dict.index('answered_correctly')\n",
    "    item_mean_idx = name_dict.index('item_mean')\n",
    "#     distance_idx = name_dict.index('task_set_distance')\n",
    "    \n",
    "    for i in step:\n",
    "        tmp = tmp_g[:beg]\n",
    "        selected_part = tmp_g[beg, part_idx]\n",
    "        idx_list = []\n",
    "        data = np.where(tmp[:, part_idx] == selected_part)[0]\n",
    "        idx = np.where(np.diff(data) != 1)[0] + 1\n",
    "        if idx.shape[0] > 0:\n",
    "            for cnt in range(idx.shape[0] + 1):\n",
    "                if cnt == 0:\n",
    "                    idx_list.append(data[np.arange(idx[cnt])])\n",
    "                elif cnt == idx.shape[0]:\n",
    "                    idx_list.append(data[idx[cnt - 1]:])\n",
    "                else:\n",
    "                    idx_list.append(data[np.arange(idx[cnt - 1], idx[cnt])])\n",
    "        else:\n",
    "            if data.shape[0] > 0:\n",
    "                idx_list.append(data)\n",
    "                \n",
    "        if len(idx_list) > 0:\n",
    "            last_group = idx_list[-1]\n",
    "        else:\n",
    "            last_group = np.full((0, ), np.nan, dtype=np.int64)\n",
    "            \n",
    "        if last_group.shape[0] > 0:\n",
    "            time_begin = tmp[last_group[0], time_idx]\n",
    "            time_end = tmp[last_group[-1], time_idx]\n",
    "            answer_ratio = np.mean(tmp[last_group, answer_idx])\n",
    "            answer_sum = np.sum(tmp[last_group, answer_idx])\n",
    "            answer_count = tmp[last_group, answer_idx].shape[0]\n",
    "            part_time_diff = \\\n",
    "            tmp[last_group, time_idx] - np.concatenate((np.full(1, np.nan), tmp[last_group, time_idx][:-1]))\n",
    "            item_mean_group = tmp[last_group, item_mean_idx]\n",
    "        else:\n",
    "            time_begin = np.nan\n",
    "            time_end = np.nan\n",
    "            answer_ratio = np.nan\n",
    "            answer_sum = np.nan\n",
    "            answer_count = np.nan\n",
    "            part_time_diff = np.full((1, ), np.nan)\n",
    "            item_mean_group = np.full((1, ), np.nan)\n",
    "#             task_set_group = np.full((1, ), np.nan)\n",
    "            \n",
    "        begin_diff = tmp_g[beg, time_idx] - time_begin\n",
    "        end_diff = tmp_g[beg, time_idx] - time_end\n",
    "        time_last = time_end - time_begin\n",
    "        time_diff_mean = np.nanmean(part_time_diff)\n",
    "        time_diff_median = np.nanmedian(part_time_diff)\n",
    "    \n",
    "        part_group[beg:beg + i, 0] = begin_diff\n",
    "        part_group[beg:beg + i, 1] = end_diff\n",
    "        part_group[beg:beg + i, 2] = time_last\n",
    "        part_group[beg:beg + i, 3] = time_diff_mean\n",
    "        part_group[beg:beg + i, 4] = answer_ratio\n",
    "        part_group[beg:beg + i, 5] = answer_sum\n",
    "        part_group[beg:beg + i, 6] = answer_count\n",
    "        part_group[beg:beg + i, 7] = np.mean(item_mean_group)\n",
    "        part_group[beg:beg + i, 8] = np.median(item_mean_group)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        beg += i\n",
    "    return part_group\n",
    "\n",
    "# np.full((tmp_g.shape[0], m), np.nan)\n",
    "@jit(nopython = True)\n",
    "def full_group_cal(tmp_g, step, name_dict):\n",
    "    beg = 0\n",
    "    m = 2\n",
    "    ret1 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret2 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret3 = np.zeros((tmp_g.shape[0], m))\n",
    "    \n",
    "    ret4 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret6 = np.zeros((tmp_g.shape[0], m))\n",
    "    ret7 = np.zeros((tmp_g.shape[0], m))\n",
    "    \n",
    "    ret8 = np.zeros((tmp_g.shape[0], 7))\n",
    "    \n",
    "    ret9 = np.zeros((tmp_g.shape[0], 6 + 3 + 2))\n",
    "#     ret10 = np.zeros((tmp_g.shape[0], 2 + 2))\n",
    "\n",
    "#     ret10 = np.full((tmp_g.shape[0], 7), np.nan)\n",
    "    part_idx = name_dict.index('part')\n",
    "    time_idx = name_dict.index('timestamp')\n",
    "    item_mean_idx = name_dict.index('item_mean')\n",
    "    distance_idx = name_dict.index('task_set_distance')\n",
    "    answer_idx = name_dict.index('answered_correctly')\n",
    "    content_idx = name_dict.index('content_id')\n",
    "    for i in step:\n",
    "        tmp = tmp_g[:beg]\n",
    "        selected_part = tmp_g[beg, part_idx]\n",
    "        group_idx = np.where(tmp[:, part_idx] == selected_part)[0]\n",
    "        if group_idx.shape[0] > 0:\n",
    "            tmp_group = tmp[group_idx]\n",
    "            idx1 = np.where(tmp_group[:,  answer_idx] == 0)[0]\n",
    "            if idx1.shape[0] > 0:\n",
    "                wrong_time_diff = tmp_group[idx1, time_idx] - np.concatenate((np.full(1, np.nan), \n",
    "                                                                              tmp_group[idx1, time_idx][:-1]))\n",
    "                ret1[beg:beg+i, 0] = np.nanmean(tmp_group[idx1, item_mean_idx])\n",
    "                ret1[beg:beg+i, 1] = np.nanmedian(tmp_group[idx1, item_mean_idx])\n",
    "        \n",
    "                ret2[beg:beg+i, 0] = np.nanmean(tmp_group[idx1, distance_idx])\n",
    "                ret2[beg:beg+i, 1] = np.nanmedian(tmp_group[idx1, distance_idx])\n",
    "            \n",
    "                ret6[beg:beg+i, 0] = np.nanmean(wrong_time_diff)\n",
    "                ret6[beg:beg+i, 1] = np.nanmedian(wrong_time_diff)\n",
    "\n",
    "                ret9[beg:beg+i, 9] = \\\n",
    "                (tmp_g[beg, time_idx] - tmp[idx1[-1], time_idx])/(1e-6 + ret6[beg, 1])\n",
    "                \n",
    "            idx2 = np.where(tmp_group[:, answer_idx] == 1)[0]\n",
    "            if idx2.shape[0] > 0:\n",
    "                right_time_diff = tmp_group[idx2, time_idx] - np.concatenate((np.full(1, np.nan),\n",
    "                                                                              tmp_group[idx2, time_idx][:-1]))\n",
    "                ret3[beg:beg+i, 0] = np.nanmean(tmp_group[idx2, item_mean_idx])\n",
    "                ret3[beg:beg+i, 1] = np.nanmedian(tmp_group[idx2, item_mean_idx])\n",
    "            \n",
    "                ret4[beg:beg+i, 0] = np.nanmean(tmp_group[idx2, distance_idx])\n",
    "                ret4[beg:beg+i, 1] = np.nanmedian(tmp_group[idx2, distance_idx])\n",
    "            \n",
    "                ret7[beg:beg+i, 0] = np.nanmean(right_time_diff)\n",
    "                ret7[beg:beg+i, 1] = np.nanmedian(right_time_diff)\n",
    "                \n",
    "                ret9[beg:beg+i, 10] = \\\n",
    "                (tmp_g[beg, time_idx] - tmp[idx2[-1], time_idx])/(1e-6 + ret7[beg, 1])\n",
    "                \n",
    "\n",
    "\n",
    "            ret8[beg:beg+i, 0] = np.nansum(tmp_group[:, answer_idx])\n",
    "            ret8[beg:beg+i, 1] = tmp_group[:, answer_idx].shape[0]\n",
    "            ret8[beg:beg+i, 2] = np.nanmean(tmp_group[:, answer_idx])\n",
    "            ret8[beg:beg+i, 3] = ret8[beg:beg+i, 1]/tmp.shape[0]\n",
    "            ret8[beg:beg+i, 4] = ret8[beg:beg+i, 0]/tmp.shape[0]\n",
    "            \n",
    "            \n",
    "\n",
    "            ret8[beg:beg+i, 5] = \\\n",
    "            (tmp_g[beg, time_idx] - tmp[group_idx[-1], time_idx])/(1e-6 + np.nanmedian(wrong_time_diff))\n",
    "            ret8[beg:beg+i, 6] = \\\n",
    "            (tmp_g[beg, time_idx] - tmp[group_idx[-1], time_idx])/(1e-6 + np.nanmedian(right_time_diff))\n",
    "            \n",
    "\n",
    "            \n",
    "            ret9[beg:beg+i, 0] = np.nansum(tmp_group[-1:, answer_idx])\n",
    "            ret9[beg:beg+i, 1] = np.nanmean(tmp_group[-1:, answer_idx])\n",
    "            \n",
    "            ret9[beg:beg+i, 2] = np.nansum(tmp_group[-5:, answer_idx])\n",
    "            ret9[beg:beg+i, 3] = np.nanmean(tmp_group[-5:, answer_idx])\n",
    "            \n",
    "            ret9[beg:beg+i, 4] = np.nansum(tmp_group[-10:, answer_idx])\n",
    "            ret9[beg:beg+i, 5] = np.nanmean(tmp_group[-10:, answer_idx])\n",
    "\n",
    "            short_time_diff = tmp_group[-5:, time_idx] - np.concatenate((np.full(1, np.nan),\n",
    "                                                       tmp_group[-5:, time_idx][:-1]))\n",
    "            ret9[beg:beg+i, 6] = \\\n",
    "            (tmp_g[beg, time_idx] - tmp[group_idx[-1], time_idx])/(1e-6 + np.nanmedian(short_time_diff))\n",
    "            \n",
    "            short_time_diff = tmp_group[-10:, time_idx] - np.concatenate((np.full(1, np.nan),\n",
    "                                                       tmp_group[-10:, time_idx][:-1]))\n",
    "            ret9[beg:beg+i, 7] = \\\n",
    "            (tmp_g[beg, time_idx] - tmp[group_idx[-1], time_idx])/(1e-6 + np.nanmedian(short_time_diff))\n",
    "            \n",
    "\n",
    "            short_time_diff = tmp_group[-20:, time_idx] - np.concatenate((np.full(1, np.nan),\n",
    "                                                       tmp_group[-20:, time_idx][:-1]))\n",
    "            ret9[beg:beg+i, 8] = \\\n",
    "            (tmp_g[beg, time_idx] - tmp[group_idx[-1], time_idx])/(1e-6 + np.nanmedian(short_time_diff))\n",
    "            \n",
    "#             ret9[beg:beg+i, 10] = np.nanmean(short_time_diff)\n",
    "#             ret9[beg:beg+i, 11] = np.nanmedian(short_time_diff)\n",
    "            \n",
    "        beg += i\n",
    "#     ret = np.concatenate((ret1, ret2, ret3, ret4, ret8, ret9), axis = 1)\n",
    "    ret = np.concatenate((ret1, ret2, ret6, ret3, ret4, ret7, ret8, ret9), axis = 1)\n",
    "#     ret = np.concatenate((ret1, ret2, ret3), axis = 1)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def user_answer_cal(tmp_g, step, name_dict, item_answer):\n",
    "    beg = 0\n",
    "    \n",
    "    content_idx = name_dict.index('content_id')\n",
    "    time_idx = name_dict.index('timestamp')\n",
    "    item_mean_idx = name_dict.index('item_mean')\n",
    "    answer_idx = name_dict.index('answered_correctly')\n",
    "    user_answer_idx = name_dict.index('user_answer')\n",
    "    distance_idx = name_dict.index('task_set_distance')\n",
    "    item_answer_idx = name_dict.index('correct_answer')\n",
    "    part_idx = name_dict.index('part')\n",
    "    \n",
    "    ans = np.zeros((tmp_g.shape[0], 1),)\n",
    "    tmp_ans = item_answer[tmp_g[:,content_idx].astype(np.uint16), :]\n",
    "    for k in range(tmp_ans.shape[0]):\n",
    "        ans[k] = tmp_ans[k, np.uint8(tmp_g[k, user_answer_idx])]\n",
    "        \n",
    "#     m = \n",
    "    ret1 =  np.zeros((tmp_g.shape[0], 2))\n",
    "    ret2 = np.zeros((tmp_g.shape[0], 3 * 2))\n",
    "    ret3 = np.zeros((tmp_g.shape[0], 2 * 2))\n",
    "    ret4 = np.zeros((tmp_g.shape[0], 4 + 2))\n",
    "    \n",
    "    tmp_ = np.concatenate((tmp_g, ans), axis = 1)\n",
    "    for i in step:\n",
    "        tmp = tmp_[:beg]         \n",
    "            \n",
    "        if tmp.shape[0] > 0:\n",
    "            ret1[beg:beg+i, 0] = np.mean(tmp[:, -1])\n",
    "            ret1[beg:beg+i, 1] = np.median(tmp[:, -1])\n",
    "            for j in range(i):\n",
    "                item_ans = tmp_g[beg + j, item_answer_idx]\n",
    "                ans_index = np.where(tmp[:, user_answer_idx] == item_ans)[0]\n",
    "                if ans_index.shape[0] > 0:\n",
    "                    ret2[beg+j, 0] = np.sum(tmp[ans_index, answer_idx])\n",
    "                    ret2[beg+j, 1] = np.mean(tmp[ans_index, answer_idx])\n",
    "                    ret2[beg+j, 2] = tmp[ans_index, answer_idx].shape[0]\n",
    "                    \n",
    "                    ret4[beg+j, 4] = tmp_g[beg+j, time_idx] - tmp[ans_index[-1], time_idx]\n",
    "                    \n",
    "                ans_index = np.where(tmp[:, item_answer_idx] == item_ans)[0]\n",
    "                if ans_index.shape[0] > 0:\n",
    "                    ret2[beg+j, 3] = np.sum(tmp[ans_index, answer_idx])\n",
    "                    ret2[beg+j, 4] = np.mean(tmp[ans_index, answer_idx])\n",
    "                    ret2[beg+j, 5] = tmp[ans_index, answer_idx].shape[0]\n",
    "                    \n",
    "                    ret4[beg+j, 5] = tmp_g[beg+j, time_idx] - tmp[ans_index[-1], time_idx]\n",
    "        \n",
    "                    \n",
    "            idx1 = np.where(tmp[:,  answer_idx] == 0)[0]\n",
    "            if idx1.shape[0] > 0:\n",
    "                y = np.bincount(tmp[idx1, user_answer_idx].astype(np.uint8))\n",
    "                ii = np.nonzero(y)[0]\n",
    "                tmp_y = np.vstack((ii, y[ii])).T\n",
    "                \n",
    "                ret3[beg:beg+i, 0] = tmp_y[:,0][np.argmax(tmp_y[:,1])]\n",
    "                ret3[beg:beg+i, 1] = tmp_y[:,1][np.argmax(tmp_y[:,1])]\n",
    "                \n",
    "\n",
    "            idx2 = np.where(tmp[:, answer_idx] == 1)[0]\n",
    "            if idx2.shape[0] > 0:\n",
    "                \n",
    "                y = np.bincount(tmp[idx2, user_answer_idx].astype(np.uint8))\n",
    "                ii = np.nonzero(y)[0]\n",
    "                tmp_y = np.vstack((ii, y[ii])).T\n",
    "                \n",
    "                ret3[beg:beg+i, 2] = tmp_y[:,0][np.argmax(tmp_y[:,1])]\n",
    "                ret3[beg:beg+i, 3] = tmp_y[:,1][np.argmax(tmp_y[:,1])]\n",
    "\n",
    "           \n",
    "            tmp1 = tmp[-20:,:]\n",
    "            y = np.bincount(tmp1[:,user_answer_idx].astype(np.uint8))\n",
    "            ii = np.nonzero(y)[0]\n",
    "            tmp_y = np.vstack((ii, y[ii])).T \n",
    "            ret4[beg:beg+i, 0] = tmp_y[:,0][np.argmax(tmp_y[:,1])]\n",
    "            ret4[beg:beg+i, 1] = tmp_y[:,1][np.argmax(tmp_y[:,1])]\n",
    "            \n",
    "            idx0 = np.where(tmp1[:, user_answer_idx] == np.argmax(tmp_y[:,1]))[0]\n",
    "            ret4[beg:beg+i, 2] = np.nanmean(tmp1[idx0, answer_idx])\n",
    "            ret4[beg:beg+i, 3] = np.nansum(tmp1[idx0, answer_idx])\n",
    "            \n",
    "\n",
    "#             y = np.bincount(tmp1[:, part_idx].astype(np.uint8))\n",
    "#             ii = np.nonzero(y)[0]\n",
    "#             tmp_y = np.vstack((ii, y[ii])).T \n",
    "#             ret4[beg:beg+i, 4] = ii.shape[0]\n",
    "#             ret4[beg:beg+i, 5] = np.mean(tmp_y[:,1])\n",
    "            \n",
    "        beg += i\n",
    "    ret = np.concatenate((ret1, ret2, ret3, ret4), axis = 1)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def last_group_cal_wrap(tmp_g, name_dict, item_answer_dict):\n",
    "    step = np.unique(tmp_g[:, 1], return_counts=True)[1]\n",
    "    ds1 = last_group_cal(tmp_g, step, name_dict)\n",
    "    ds2 = full_group_cal(tmp_g, step, name_dict)\n",
    "    ds3 = divide_agg(tmp_g, step, name_dict)\n",
    "    ds4 = user_answer_cal(tmp_g, step, name_dict, item_answer_dict)\n",
    "    ds = np.concatenate((ds1, ds2, ds3, ds4), axis = 1)\n",
    "    return ds\n",
    "\n",
    "from multiprocessing import Process, Manager,Pool\n",
    "from functools import partial\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "@timeit\n",
    "def parallel_last_group_wrap(group, name_dict, last_idx, item_answer_dict):\n",
    "    res = Parallel(n_jobs = 25, backend = 'loky')\\\n",
    "              (delayed(last_group_cal_wrap)(group[i], name_dict, item_answer_dict)\n",
    "              for i in tqdm(range(len(group))))\n",
    "    ans = np.concatenate(res)\n",
    "    ans = resort_array(ans, last_idx)\n",
    "    return ans\n",
    "\n",
    "\n",
    "@timeit\n",
    "def last_group_feature(g, name_dict, idx, item_answer_dict):\n",
    "    res = []\n",
    "    for i in tqdm(range(len(g))):\n",
    "        tmp_g = g[i]\n",
    "        tmp_res = last_group_cal_wrap(tmp_g, name_dict, item_answer_dict)\n",
    "        res.append(tmp_res)\n",
    "    ans = np.concatenate(res)\n",
    "    ans = resort_array(ans, idx)\n",
    "    return ans\n",
    "\n",
    "@timeit\n",
    "def valid_last_group_feature(valid_gp, rolling_gp, name_dict, valid_idx, item_answer_dict):\n",
    "    res = []\n",
    "    for i in range(len(valid_gp)):\n",
    "        tmp_g = valid_gp[i]\n",
    "        valid_shape = tmp_g.shape[0]\n",
    "        if tmp_g[0,0] in rolling_gp:\n",
    "            tmp_rolling = rolling_gp[tmp_g[0, 0]]\n",
    "            tmp_g = np.concatenate([tmp_rolling, tmp_g])\n",
    "        \n",
    "        tmp_res = last_group_cal_wrap(tmp_g, name_dict, item_answer_dict)\n",
    "        tmp_res = tmp_res[-valid_shape:]\n",
    "        res.append(tmp_res)\n",
    "    ans = np.concatenate(res)\n",
    "    ans = resort_array(ans, valid_idx)\n",
    "    return ans\n",
    "\n",
    "def pre_merge_group(valid_gp, rolling_gp):\n",
    "    valid_shape_list = []\n",
    "    for i in range(len(valid_gp)):\n",
    "        tmp_g = valid_gp[i]\n",
    "        valid_shape = tmp_g.shape[0]\n",
    "        if tmp_g[0,0] in rolling_gp:\n",
    "            tmp_rolling = rolling_gp[tmp_g[0, 0]]\n",
    "            tmp_g = np.concatenate([tmp_rolling, tmp_g])\n",
    "        valid_gp[i] = tmp_g\n",
    "        \n",
    "        valid_shape_list.append(valid_shape)\n",
    "    return valid_gp, valid_shape_list\n",
    "\n",
    "\n",
    "def valid_last_group_wrap(tmp_g, valid_shape, name_dict, item_answer_dict):\n",
    "    tmp_res = last_group_cal_wrap(tmp_g, name_dict, item_answer_dict)\n",
    "    tmp_res = tmp_res[-valid_shape:]\n",
    "    return tmp_res\n",
    "\n",
    "@timeit\n",
    "def valid_parallel_last_group_wrap(group, valid_shape_list, name_dict, valid_idx, item_answer_dict):\n",
    "    res = Parallel(n_jobs = 25, backend = 'loky')\\\n",
    "              (delayed(valid_last_group_wrap)(group[i], valid_shape_list[i], name_dict, item_answer_dict)\n",
    "              for i in tqdm(range(len(group))))\n",
    "    ans = np.concatenate(res)\n",
    "    ans = resort_array(ans, valid_idx)\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/177764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_feat_group function took 57.620 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177764/177764 [04:56<00:00, 599.21it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel_last_group_wrap function took 368.460 s\n",
      "rolling_feat_group function took 2.770 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25298/25298 [00:46<00:00, 542.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_parallel_last_group_wrap function took 79.110 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53216"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "last_group_name = []\n",
    "last_group_name += ['begin_time_diff', 'end_time_diff', 'part_duration_time', 'part_time_diff_mean']\n",
    "last_group_name += ['part_session_mean', 'part_session_sum', 'part_session_count']\n",
    "last_group_name += ['last_part_item_mean', 'last_part_item_median']\n",
    "# last_group_name += ['part_time_diff_median']\n",
    "# last_group_name += ['session_count_mean', 'session_count_std', 'session_total_count']\n",
    "\n",
    "# last_group_name += ['last_task_set_distance_mean', 'last_task_set_distance_median']\n",
    "\n",
    "# last_group_name += [f'full_group_{var}_{func}' \n",
    "#  for var in ['item_mean', 'task_set_distance', 'timestamp'] for func in ['mean', 'median']]\n",
    "last_group_name += [f'full_group{g}_{var}_{func}'  for g in [0, 1]\n",
    " for var in ['item_mean', 'task_set_distance', 'timestamp'] for func in ['mean', 'median']]\n",
    "last_group_name += ['part_sum', 'part_count', 'part_mean']\n",
    "last_group_name += ['part_count_global_ratio', 'part_sum_global_ratio']\n",
    "last_group_name += ['part_time_wrong_div', 'part_time_right_div']\n",
    "# last_group_name += ['last_part_time_wrong_div', 'last_part_time_right_div']\n",
    "\n",
    "# last_group_name += ['part_duration_answer_mean', 'part_interval_answer_mean']\n",
    "\n",
    "last_group_name += [f'part_{func}_{i}' for i in [1, 5, 10] for func in ['sum', 'mean']]\n",
    "last_group_name += ['last_5_part_time_div', 'last_10_part_time_div', \n",
    "                    'last_20_part_time_div']\n",
    "last_group_name += ['last_right_time_diff', 'last_wrong_time_diff']\n",
    "# last_group_name += ['last_part_item', 'last_part_task_set_distance',\n",
    "#                     'last_part_task_item_mean', 'last_part_time_diff']\n",
    "# last_group_name += ['item_mean_right_div', 'item_mean_wrong_div']\n",
    "\n",
    "new_func_list = ['mean', 'median']\n",
    "# , 'min', 'max', 'median'\n",
    "last_group_name += [f\"cum_answer0_{func}_{val}\" \n",
    "                 for val in ['item_mean', 'task_set_distance'] \n",
    "                 for func in new_func_list]\n",
    "last_group_name += [f\"cum_answer1_{func}_{val}\" \n",
    "                 for val in ['item_mean', 'task_set_distance'] \n",
    "                 for func in new_func_list]\n",
    "last_group_name += [\"cum_answer0_time_diff\", \"cum_answer1_time_diff\"]\n",
    "last_group_name += [f\"global_task_set_shift{i}\" for i in range(1, 6)]\n",
    "\n",
    "last_group_name += [f\"cum_answer0_{func}_{val}\" \n",
    "                 for val in ['wrong_time_diff'] \n",
    "                 for func in new_func_list]\n",
    "last_group_name += [f\"cum_answer1_{func}_{val}\" \n",
    "                 for val in ['right_time_diff'] \n",
    "                 for func in new_func_list]\n",
    "\n",
    "last_group_name += ['last_content_id_time_diff']\n",
    "last_group_name += ['content_correct_mean', 'content_correct_sum', 'content_correct_count']\n",
    "last_group_name += ['hard_answer0_time', 'hard_answer1_time']\n",
    "\n",
    "last_group_name += [f'full_bundle_{var}_{func}' \n",
    " for var in ['item_mean', 'task_set_distance', 'timestamp'] for func in ['mean', 'median']]\n",
    "last_group_name += ['bundle_sum', 'bundle_mean', 'bundle_count']\n",
    "last_group_name += ['diff_lag_median_div', 'diff_item_median_div', 'diff_time_median_div']\n",
    "last_group_name += ['diff_item_mean_div', 'diff_task_set_mean_div', 'diff_timestamp_mean_div']\n",
    "# last_group_name += ['wrong_time_diff20', 'wrong_time_diff10', 'right_time_diff20', 'right_time_diff10']\n",
    "\n",
    "\n",
    "last_group_name += [f'user_trend_{func}' for func in ['mean', 'median']]\n",
    "last_group_name += [f'user_trend_roll_{p}_{func}' \n",
    "                    for p in ['user_ans', 'item_ans'] \n",
    "                    for func in ['sum', 'mean', 'count']]\n",
    "last_group_name += [f'new_Feat{i}' for i in range(4)]\n",
    "# last_group_name += [f'part_new_Feat{i}' for i in range(4)]\n",
    "\n",
    "last_group_name += ['last_20_frequent_answer', 'last_20_frequent_answer_count',\n",
    "                    'last_20_frequent_answer_mean', 'last_20_frequent_answer_sum']\n",
    "last_group_name += ['last_user_same_answer_tf', 'last_item_same_answer_tf']\n",
    "\n",
    "item_answer_dict = train.groupby(['content_id', 'user_answer'])['user_answer'].agg('count').unstack()\n",
    "item_answer_dict.fillna(0, inplace = True)\n",
    "item_answer_dict = item_answer_dict.to_numpy()\n",
    "total_sum = np.sum(item_answer_dict, axis = 1)\n",
    "for i in range(4):\n",
    "    item_answer_dict[:, i] = item_answer_dict[:, i]/total_sum\n",
    "    \n",
    "roll_keep = ['user_id', 'timestamp', 'content_id', 'answered_correctly',\n",
    "             'prior_question_elapsed_time', 'item_mean', 'task_set_distance', 'part', 'bundle_id', \n",
    "             'user_answer', 'correct_answer']\n",
    "group, last_idx, name_dict = rolling_feat_group(X, roll_keep)\n",
    "last_group_ds = parallel_last_group_wrap(group, name_dict, last_idx, item_answer_dict)\n",
    "\n",
    "last_part_group = roll_init(group, 20000)\n",
    "# last_part_group = np.load('./local_whole_group_data_v4.npy', allow_pickle = True).item()\n",
    "\n",
    "valid_gp, valid_idx, name_dict = rolling_feat_group(valid, roll_keep)\n",
    "valid_gp, valid_shape_list = pre_merge_group(valid_gp, last_part_group)\n",
    "valid_last_group_ds = valid_parallel_last_group_wrap(valid_gp, valid_shape_list, name_dict, \n",
    "                                                     valid_idx, item_answer_dict)\n",
    "\n",
    "X[last_group_name] = pd.DataFrame(last_group_ds, index=X.index)\n",
    "valid[last_group_name] = pd.DataFrame(valid_last_group_ds, index=valid.index)\n",
    "add_feature.extend(last_group_name)\n",
    "\n",
    "del group, valid_gp, last_part_group;\n",
    "del last_group_ds, valid_last_group_ds;\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# for col in last_group_name:\n",
    "#     add_feature.remove(col)\n",
    "# X.drop(last_group_name, axis = 1, inplace = True)\n",
    "# valid.drop(last_group_name, axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26269649, number of negative: 13730351\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 15.432573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45058\n",
      "[LightGBM] [Info] Number of data points in the train set: 40000000, number of used features: 208\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.656741 -> initscore=0.648805\n",
      "[LightGBM] [Info] Start training from score 0.648805\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.794921\n",
      "[200]\tvalid_0's auc: 0.797906\n",
      "[300]\tvalid_0's auc: 0.799349\n",
      "[400]\tvalid_0's auc: 0.800123\n",
      "[500]\tvalid_0's auc: 0.80066\n",
      "[600]\tvalid_0's auc: 0.801048\n",
      "[700]\tvalid_0's auc: 0.801319\n",
      "[800]\tvalid_0's auc: 0.80155\n",
      "[900]\tvalid_0's auc: 0.801724\n",
      "[1000]\tvalid_0's auc: 0.801903\n",
      "[1100]\tvalid_0's auc: 0.802056\n",
      "[1200]\tvalid_0's auc: 0.802177\n",
      "[1300]\tvalid_0's auc: 0.802289\n",
      "[1400]\tvalid_0's auc: 0.802392\n",
      "[1500]\tvalid_0's auc: 0.802479\n",
      "[1600]\tvalid_0's auc: 0.802568\n",
      "[1700]\tvalid_0's auc: 0.802661\n",
      "[1800]\tvalid_0's auc: 0.802756\n",
      "[1900]\tvalid_0's auc: 0.802824\n",
      "[2000]\tvalid_0's auc: 0.802903\n",
      "[2100]\tvalid_0's auc: 0.802944\n",
      "[2200]\tvalid_0's auc: 0.803\n",
      "[2300]\tvalid_0's auc: 0.803056\n",
      "[2400]\tvalid_0's auc: 0.803104\n",
      "[2500]\tvalid_0's auc: 0.803154\n",
      "[2600]\tvalid_0's auc: 0.803185\n",
      "[2700]\tvalid_0's auc: 0.803234\n",
      "[2800]\tvalid_0's auc: 0.803264\n",
      "[2900]\tvalid_0's auc: 0.803315\n",
      "[3000]\tvalid_0's auc: 0.803345\n",
      "[3100]\tvalid_0's auc: 0.803365\n",
      "[3200]\tvalid_0's auc: 0.803403\n",
      "[3300]\tvalid_0's auc: 0.803431\n",
      "[3400]\tvalid_0's auc: 0.803455\n",
      "[3500]\tvalid_0's auc: 0.803483\n",
      "[3600]\tvalid_0's auc: 0.803517\n",
      "[3700]\tvalid_0's auc: 0.803536\n",
      "[3800]\tvalid_0's auc: 0.803554\n",
      "[3900]\tvalid_0's auc: 0.803568\n",
      "[4000]\tvalid_0's auc: 0.803578\n",
      "[4100]\tvalid_0's auc: 0.80359\n",
      "[4200]\tvalid_0's auc: 0.80361\n",
      "[4300]\tvalid_0's auc: 0.803623\n",
      "[4400]\tvalid_0's auc: 0.80363\n",
      "[4500]\tvalid_0's auc: 0.803639\n",
      "[4600]\tvalid_0's auc: 0.803655\n",
      "Early stopping, best iteration is:\n",
      "[4614]\tvalid_0's auc: 0.803657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_feature = ['prior_question_elapsed_time', 'prior_question_had_explanation', 'content_id']\n",
    "features = basic_feature + add_feature\n",
    "# features = [col for col in features if col not in ['wrong_frequent_part', 'wrong_frequent_part_count',\n",
    "#                     'right_frequent_part', 'right_frequent_part_count']]\n",
    "target = 'answered_correctly'\n",
    "# X.fillna(0, inplace = True)\n",
    "# valid.fillna(0, inplace = True)\n",
    "\n",
    "lgb_train = lgb.Dataset(X[features].values.astype(np.float32), \n",
    "                        X[target].values.astype(np.float32), feature_name=features)\n",
    "lgb_valid = lgb.Dataset(valid[features].values.astype(np.float32), \n",
    "                        valid[target].values.astype(np.float32), feature_name=features)\n",
    "# del X, valid;\n",
    "# del train;\n",
    "gc.collect()\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 63,\n",
    "    'metrics':'auc',\n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "\n",
    "model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_valid],\n",
    "                    verbose_eval=100,\n",
    "                    num_boost_round=30000,\n",
    "                    early_stopping_rounds=50\n",
    "                 )\n",
    "\n",
    "del lgb_train,lgb_valid;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13067459, number of negative: 6932541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.954772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 45060\n",
      "[LightGBM] [Info] Number of data points in the train set: 20000000, number of used features: 208\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653373 -> initscore=0.633899\n",
      "[LightGBM] [Info] Start training from score 0.633899\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.794862\n",
      "[200]\tvalid_0's auc: 0.797873\n",
      "[300]\tvalid_0's auc: 0.79917\n",
      "[400]\tvalid_0's auc: 0.799844\n",
      "[500]\tvalid_0's auc: 0.800315\n",
      "[600]\tvalid_0's auc: 0.800603\n",
      "[700]\tvalid_0's auc: 0.80086\n",
      "[800]\tvalid_0's auc: 0.801068\n",
      "[900]\tvalid_0's auc: 0.801218\n",
      "[1000]\tvalid_0's auc: 0.801335\n",
      "[1100]\tvalid_0's auc: 0.801434\n",
      "[1200]\tvalid_0's auc: 0.80154\n",
      "[1300]\tvalid_0's auc: 0.801656\n",
      "[1400]\tvalid_0's auc: 0.801763\n",
      "[1500]\tvalid_0's auc: 0.80183\n",
      "[1600]\tvalid_0's auc: 0.801896\n",
      "[1700]\tvalid_0's auc: 0.80195\n",
      "[1800]\tvalid_0's auc: 0.801977\n",
      "[1900]\tvalid_0's auc: 0.802012\n",
      "[2000]\tvalid_0's auc: 0.802048\n",
      "[2100]\tvalid_0's auc: 0.802071\n",
      "[2200]\tvalid_0's auc: 0.802104\n",
      "[2300]\tvalid_0's auc: 0.802161\n",
      "[2400]\tvalid_0's auc: 0.802187\n",
      "[2500]\tvalid_0's auc: 0.802212\n",
      "[2600]\tvalid_0's auc: 0.802227\n",
      "Early stopping, best iteration is:\n",
      "[2608]\tvalid_0's auc: 0.802229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_feature = ['prior_question_elapsed_time', 'prior_question_had_explanation', 'content_id']\n",
    "features = basic_feature + add_feature\n",
    "# features = [col for col in features if col not in ['wrong_frequent_part', 'wrong_frequent_part_count',\n",
    "#                     'right_frequent_part', 'right_frequent_part_count']]\n",
    "target = 'answered_correctly'\n",
    "# X.fillna(0, inplace = True)\n",
    "# valid.fillna(0, inplace = True)\n",
    "\n",
    "lgb_train = lgb.Dataset(X[features].values.astype(np.float32), \n",
    "                        X[target].values.astype(np.float32), feature_name=features)\n",
    "lgb_valid = lgb.Dataset(valid[features].values.astype(np.float32), \n",
    "                        valid[target].values.astype(np.float32), feature_name=features)\n",
    "# del X, valid;\n",
    "# del train;\n",
    "gc.collect()\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 63,\n",
    "    'metrics':'auc',\n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "\n",
    "model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_valid],\n",
    "                    verbose_eval=100,\n",
    "                    num_boost_round=30000,\n",
    "                    early_stopping_rounds=50\n",
    "                 )\n",
    "\n",
    "del lgb_train,lgb_valid;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13067459, number of negative: 6932541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.836194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 44550\n",
      "[LightGBM] [Info] Number of data points in the train set: 20000000, number of used features: 206\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653373 -> initscore=0.633899\n",
      "[LightGBM] [Info] Start training from score 0.633899\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.794773\n",
      "[200]\tvalid_0's auc: 0.797672\n",
      "[300]\tvalid_0's auc: 0.798981\n",
      "[400]\tvalid_0's auc: 0.799653\n",
      "[500]\tvalid_0's auc: 0.800148\n",
      "[600]\tvalid_0's auc: 0.800485\n",
      "[700]\tvalid_0's auc: 0.800737\n",
      "[800]\tvalid_0's auc: 0.800934\n",
      "[900]\tvalid_0's auc: 0.801104\n",
      "[1000]\tvalid_0's auc: 0.801264\n",
      "[1100]\tvalid_0's auc: 0.801387\n",
      "[1200]\tvalid_0's auc: 0.801489\n",
      "[1300]\tvalid_0's auc: 0.801555\n",
      "[1400]\tvalid_0's auc: 0.80164\n",
      "[1500]\tvalid_0's auc: 0.801712\n",
      "[1600]\tvalid_0's auc: 0.801771\n",
      "[1700]\tvalid_0's auc: 0.801802\n",
      "[1800]\tvalid_0's auc: 0.801851\n",
      "[1900]\tvalid_0's auc: 0.801885\n",
      "[2000]\tvalid_0's auc: 0.801929\n",
      "[2100]\tvalid_0's auc: 0.80197\n",
      "[2200]\tvalid_0's auc: 0.802027\n",
      "[2300]\tvalid_0's auc: 0.802073\n",
      "[2400]\tvalid_0's auc: 0.802082\n",
      "[2500]\tvalid_0's auc: 0.802107\n",
      "[2600]\tvalid_0's auc: 0.802128\n",
      "[2700]\tvalid_0's auc: 0.80214\n",
      "[2800]\tvalid_0's auc: 0.802169\n",
      "[2900]\tvalid_0's auc: 0.802183\n",
      "[3000]\tvalid_0's auc: 0.802214\n",
      "[3100]\tvalid_0's auc: 0.802221\n",
      "[3200]\tvalid_0's auc: 0.802232\n",
      "[3300]\tvalid_0's auc: 0.802238\n",
      "[3400]\tvalid_0's auc: 0.802244\n",
      "Early stopping, best iteration is:\n",
      "[3390]\tvalid_0's auc: 0.802247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "602"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_feature = ['prior_question_elapsed_time', 'prior_question_had_explanation', 'content_id']\n",
    "features = basic_feature + add_feature\n",
    "# features = [col for col in features if col not in ['wrong_frequent_part', 'wrong_frequent_part_count',\n",
    "#                     'right_frequent_part', 'right_frequent_part_count']]\n",
    "target = 'answered_correctly'\n",
    "# X.fillna(0, inplace = True)\n",
    "# valid.fillna(0, inplace = True)\n",
    "\n",
    "lgb_train = lgb.Dataset(X[features].values.astype(np.float32), \n",
    "                        X[target].values.astype(np.float32), feature_name=features)\n",
    "lgb_valid = lgb.Dataset(valid[features].values.astype(np.float32), \n",
    "                        valid[target].values.astype(np.float32), feature_name=features)\n",
    "# del X, valid;\n",
    "# del train;\n",
    "gc.collect()\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 63,\n",
    "    'metrics':'auc',\n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "\n",
    "model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_valid],\n",
    "                    verbose_eval=100,\n",
    "                    num_boost_round=30000,\n",
    "                    early_stopping_rounds=50\n",
    "                 )\n",
    "\n",
    "del lgb_train,lgb_valid;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 13067459, number of negative: 6932541\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 6.809473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 43275\n",
      "[LightGBM] [Info] Number of data points in the train set: 20000000, number of used features: 201\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653373 -> initscore=0.633899\n",
      "[LightGBM] [Info] Start training from score 0.633899\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.794571\n",
      "[200]\tvalid_0's auc: 0.79753\n",
      "[300]\tvalid_0's auc: 0.798824\n",
      "[400]\tvalid_0's auc: 0.799528\n",
      "[500]\tvalid_0's auc: 0.799948\n",
      "[600]\tvalid_0's auc: 0.800284\n",
      "[700]\tvalid_0's auc: 0.800523\n",
      "[800]\tvalid_0's auc: 0.800703\n",
      "[900]\tvalid_0's auc: 0.800934\n",
      "[1000]\tvalid_0's auc: 0.801054\n",
      "[1100]\tvalid_0's auc: 0.801171\n",
      "[1200]\tvalid_0's auc: 0.801245\n",
      "[1300]\tvalid_0's auc: 0.801382\n",
      "[1400]\tvalid_0's auc: 0.801473\n",
      "[1500]\tvalid_0's auc: 0.801522\n",
      "[1600]\tvalid_0's auc: 0.801603\n",
      "[1700]\tvalid_0's auc: 0.801664\n",
      "[1800]\tvalid_0's auc: 0.801725\n",
      "[1900]\tvalid_0's auc: 0.801775\n",
      "[2000]\tvalid_0's auc: 0.801833\n",
      "[2100]\tvalid_0's auc: 0.801891\n",
      "[2200]\tvalid_0's auc: 0.801913\n",
      "[2300]\tvalid_0's auc: 0.801953\n",
      "[2400]\tvalid_0's auc: 0.801987\n",
      "[2500]\tvalid_0's auc: 0.802015\n",
      "[2600]\tvalid_0's auc: 0.802032\n",
      "[2700]\tvalid_0's auc: 0.802053\n",
      "[2800]\tvalid_0's auc: 0.802062\n",
      "[2900]\tvalid_0's auc: 0.80208\n",
      "Early stopping, best iteration is:\n",
      "[2949]\tvalid_0's auc: 0.802096\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "474"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_feature = ['prior_question_elapsed_time', 'prior_question_had_explanation', 'content_id']\n",
    "features = basic_feature + add_feature\n",
    "# features = [col for col in features if col not in ['wrong_frequent_part', 'wrong_frequent_part_count',\n",
    "#                     'right_frequent_part', 'right_frequent_part_count']]\n",
    "target = 'answered_correctly'\n",
    "# X.fillna(0, inplace = True)\n",
    "# valid.fillna(0, inplace = True)\n",
    "\n",
    "lgb_train = lgb.Dataset(X[features].values.astype(np.float32), \n",
    "                        X[target].values.astype(np.float32), feature_name=features)\n",
    "lgb_valid = lgb.Dataset(valid[features].values.astype(np.float32), \n",
    "                        valid[target].values.astype(np.float32), feature_name=features)\n",
    "# del X, valid;\n",
    "# del train;\n",
    "gc.collect()\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_leaves': 63,\n",
    "    'metrics':'auc',\n",
    "    'n_jobs':-1\n",
    "}\n",
    "\n",
    "\n",
    "model = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_valid],\n",
    "                    verbose_eval=100,\n",
    "                    num_boost_round=30000,\n",
    "                    early_stopping_rounds=50\n",
    "                 )\n",
    "\n",
    "del lgb_train,lgb_valid;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X[['div_ratio1', 'div_ratio2', 'div_ratio3'] + \\\n",
    "#  [f'new_Feat{i}' for i in range(4)] + \\\n",
    "#  ['part_time_wrong_div', 'part_time_right_div'] +\\\n",
    "#  ['diff_lag_median_div', 'diff_item_median_div', 'diff_time_median_div'] +\\\n",
    "# ['diff_item_mean_div', 'diff_task_set_mean_div', 'diff_timestamp_mean_div'] +\\\n",
    "#  ['last_20_frequent_answer', 'last_20_frequent_answer_count',\n",
    "#                     'last_20_frequent_answer_mean', \n",
    "#   'last_20_frequent_answer_sum']].astype(np.float32).to_feather(\"changed_feature.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# valid[['div_ratio1', 'div_ratio2', 'div_ratio3'] + \\\n",
    "#  [f'new_Feat{i}' for i in range(4)] + \\\n",
    "#  ['part_time_wrong_div', 'part_time_right_div'] +\\\n",
    "#  ['diff_lag_median_div', 'diff_item_median_div', 'diff_time_median_div'] +\\\n",
    "# ['diff_item_mean_div', 'diff_task_set_mean_div', 'diff_timestamp_mean_div'] +\\\n",
    "#  ['last_20_frequent_answer', 'last_20_frequent_answer_count',\n",
    "#                     'last_20_frequent_answer_mean', \n",
    "#   'last_20_frequent_answer_sum']].astype(np.float32).to_feather(\"vaild_changed_feature.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model_fusion_last_v2_4000wdata.pkl', 'rb') as fin:\n",
    "    model = pickle.load(fin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_dict_init_ function took 6.400 s\n",
      "content_encoder1 function took 27.600 s\n",
      "content_encoder2 function took 11.390 s\n",
      "read_enc_data function took 0.070 s\n",
      "content_emb_dict_init_ function took 45.460 s\n"
     ]
    }
   ],
   "source": [
    "# @timeit\n",
    "def get_answer_dict(train):\n",
    "    item_answer = train.groupby(['content_id', 'user_answer'])['user_answer'].agg('count').unstack()\n",
    "    item_answer.fillna(0, inplace = True)\n",
    "    item_answer = item_answer.to_numpy()\n",
    "    total_sum = np.sum(item_answer, axis = 1)\n",
    "    for i in range(4):\n",
    "        item_answer[:, i] = item_answer[:, i]/total_sum\n",
    "    return item_answer\n",
    "\n",
    "content_emb_dict, content_emb_cols = content_emb_dict_init_(train)\n",
    "\n",
    "questions = pd.read_csv('./questions.csv')\n",
    "item_answer_dict = get_answer_dict(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_dict function took 6.360 s\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(code_path + 'beta_fusion_test_script')\n",
    "from test_user_feature import initial_dict\n",
    "from test_state_feature import initial_attempt, dict_trans\n",
    "from test_content_encoding import content_emb_dict_init_\n",
    "# from test_part_feature import part_dict_init\n",
    "from test_bundle_feature import bundle_dict_init\n",
    "\n",
    "\n",
    "user_dict, item_dict = initial_dict(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat5_group function took 39.010 s\n"
     ]
    }
   ],
   "source": [
    "from feat_group5 import feat5_group,roll_init\n",
    "from test_rolling_feature import rolling_feat_group\n",
    "\n",
    "prior_question_elapsed_time_mean = train.prior_question_elapsed_time.dropna().values.mean()\n",
    "\n",
    "group5, g5_idx = feat5_group(X)\n",
    "rolling_gp = roll_init(group5, 50)\n",
    "\n",
    "\n",
    "roll_keep = ['user_id', 'timestamp', 'content_id', 'answered_correctly',\n",
    "             'prior_question_elapsed_time', 'item_mean', 'task_set_distance', 'part', 'bundle_id', \n",
    "             'user_answer', 'correct_answer']\n",
    "group, roll_idx, name_dict = rolling_feat_group(X, roll_keep)\n",
    "whole_group_roll = roll_init(group, 20000)\n",
    "del group, roll_idx;gc.collect()\n",
    "del group5;\n",
    "# del X;gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from test_user_feature import test_user\n",
    "from test_state_feature import state_feature\n",
    "from test_item_feature import test_item\n",
    "from test_user_feature import update_user_dict\n",
    "from test_content_encoding import initial_embedding_feature\n",
    "from test_feat5_group_feature import feat5_group, test_feats5_wrap\n",
    "from test_rolling_feature import test_rolling_feature_wrapper\n",
    "from test_part_feature import test_part_feature\n",
    "from test_bundle_feature import test_bundle_feature\n",
    "from test_global_group_feature import test_last_group_feature, get_last_name\n",
    "\n",
    "######\n",
    "from test_part_feature import update_part_dict\n",
    "from test_bundle_feature import update_bundle_dict\n",
    "from test_feat5_group_feature import rolling_df_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aff71528e2045548a010a77de6ca767"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "previous_test_df = None\n",
    "# del train;gc.collect()\n",
    "\n",
    "ans_map_dict = questions.set_index(['question_id'])['correct_answer'].to_dict()\n",
    "roll_keep = ['user_id', 'timestamp', 'content_id', 'answered_correctly',\n",
    "             'prior_question_elapsed_time', 'item_mean', 'task_set_distance', 'part', 'bundle_id', \n",
    "             'user_answer', 'correct_answer']\n",
    "\n",
    "pbar = tqdm(total=valid.shape[0])\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for (current_test, current_prediction_df) in iter_test:\n",
    "    if previous_test_df is not None:\n",
    "        tmp_array = np.array(eval(current_test[\"prior_group_answers_correct\"].iloc[0]))\n",
    "        tmp_array = tmp_array[tmp_array != -1]\n",
    "\n",
    "        tmp_ans = np.array(eval(current_test[\"prior_group_responses\"].iloc[0]))\n",
    "        tmp_ans = tmp_ans[tmp_ans != -1]\n",
    "        \n",
    "        previous_test_df['answered_correctly'] = tmp_array\n",
    "        previous_test_df['user_answer'] = tmp_ans\n",
    "        user_dict = update_user_dict(user_dict, previous_test_df)\n",
    "        \n",
    "        test_group, test_idx = feat5_group(previous_test_df)\n",
    "        rolling_gp = rolling_df_update(rolling_gp, test_group)\n",
    "        \n",
    "        test_roll_gp, test_roll_idx, name_dict = rolling_feat_group(previous_test_df, roll_keep)\n",
    "        whole_group_roll = rolling_df_update(whole_group_roll, test_roll_gp)\n",
    "        \n",
    "    \n",
    "    current_test = current_test[current_test.content_type_id == 0].reset_index(drop = True)\n",
    "\n",
    "    current_test['answered_correctly'] = np.nan\n",
    "    current_test['user_answer'] = np.nan\n",
    "    test_ds1 = test_user(current_test, user_dict)\n",
    "    test_ds3 = test_item(current_test, item_dict)\n",
    "    current_test[test_ds1.columns] = test_ds1\n",
    "    current_test[test_ds3.columns] = test_ds3\n",
    "    \n",
    "    test_content_emb_ds = initial_embedding_feature(current_test, content_emb_dict)\n",
    "    current_test[content_emb_cols] = pd.DataFrame(test_content_emb_ds, index = current_test.index)\n",
    "    \n",
    "    test_ds5, col_name = test_feats5_wrap(current_test, rolling_gp)\n",
    "    current_test[col_name] = pd.DataFrame(test_ds5, index = current_test.index)\n",
    "    \n",
    "    test_roll_ds, rolling_name = test_rolling_feature_wrapper(current_test, whole_group_roll, roll_keep)\n",
    "    current_test[rolling_name] = pd.DataFrame(test_roll_ds, index = current_test.index)\n",
    "\n",
    "\n",
    "    \n",
    "    test_gp, valid_idx, name_dict = rolling_feat_group(current_test, roll_keep)\n",
    "    test_last_group_ds = test_last_group_feature(test_gp, whole_group_roll, name_dict, \n",
    "                                                 valid_idx, item_answer_dict)\n",
    "    last_group_name = get_last_name()\n",
    "    current_test[last_group_name] = pd.DataFrame(test_last_group_ds, index=current_test.index)\n",
    "    current_test['prior_question_elapsed_time'] = current_test.prior_question_elapsed_time.fillna(prior_question_elapsed_time_mean)\n",
    "    current_test['prior_question_had_explanation'] = current_test.prior_question_had_explanation.fillna(False).astype('int8')\n",
    "\n",
    "    features = model.feature_name()\n",
    "    current_test['answered_correctly'] = model.predict(current_test[features])\n",
    "    \n",
    "    set_predict(current_test.loc[:,['row_id', 'answered_correctly']])\n",
    "    pbar.update(len(current_test))\n",
    "    previous_test_df = current_test.copy()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.8018066807922463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 196158/200000 [1:04:01<02:25, 26.39it/s]"
     ]
    }
   ],
   "source": [
    "validaten_flg = True\n",
    "if validaten_flg:\n",
    "    #validation score\n",
    "    y_true = valid[valid.content_type_id == 0].answered_correctly\n",
    "    y_pred = pd.concat(predicted).answered_correctly\n",
    "    print('validation auc:',roc_auc_score(y_true, y_pred))\n",
    "    \n",
    "# validation auc: 0.7891487195971285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation auc: 0.8036493507292498\n"
     ]
    }
   ],
   "source": [
    "validaten_flg = True\n",
    "if validaten_flg:\n",
    "    #validation score\n",
    "    y_true = valid[valid.content_type_id == 0].answered_correctly\n",
    "    y_pred = pd.concat(predicted).answered_correctly\n",
    "    print('validation auc:',roc_auc_score(y_true, y_pred))\n",
    "    \n",
    "# validation auc: 0.7891487195971285"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([\"user_id\", \"content_id\", \"part\", \"task_container_id\", \n",
    "            \"prior_question_elapsed_time\", \"timestamp\",\"user_mean\", \n",
    "            \"answered_correctly\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "validaten_flg = True\n",
    "valid = pd.read_pickle(valid_pickle)[:100000]\n",
    "if validaten_flg:\n",
    "    iter_test = Iter_Valid(valid,max_user=1000)\n",
    "    predicted = []\n",
    "    def set_predict(df):\n",
    "        predicted.append(df)\n",
    "else:\n",
    "    import riiideducation\n",
    "    env = riiideducation.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "    set_predict = env.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Iter_Valid(object):\n",
    "    def __init__(self, df, max_user=1000):\n",
    "        df = df.reset_index(drop=True)\n",
    "        self.df = df\n",
    "        self.user_answer = df['user_answer'].astype(str).values\n",
    "        self.answered_correctly = df['answered_correctly'].astype(str).values\n",
    "        df['prior_group_responses'] = \"[]\"\n",
    "        df['prior_group_answers_correct'] = \"[]\"\n",
    "        self.sample_df = df[df['content_type_id'] == 0][['row_id']]\n",
    "        self.sample_df['answered_correctly'] = 0\n",
    "        self.len = len(df)\n",
    "        self.user_id = df.user_id.values\n",
    "        self.task_container_id = df.task_container_id.values\n",
    "        self.content_type_id = df.content_type_id.values\n",
    "        self.max_user = max_user\n",
    "        self.current = 0\n",
    "        self.pre_user_answer_list = []\n",
    "        self.pre_answered_correctly_list = []\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def fix_df(self, user_answer_list, answered_correctly_list, pre_start):\n",
    "        df= self.df[pre_start:self.current].copy()\n",
    "        sample_df = self.sample_df[pre_start:self.current].copy()\n",
    "        df.loc[pre_start,'prior_group_responses'] = '[' + \",\".join(self.pre_user_answer_list) + ']'\n",
    "        df.loc[pre_start,'prior_group_answers_correct'] = '[' + \",\".join(self.pre_answered_correctly_list) + ']'\n",
    "        self.pre_user_answer_list = user_answer_list\n",
    "        self.pre_answered_correctly_list = answered_correctly_list\n",
    "        return df, sample_df\n",
    "\n",
    "    def __next__(self):\n",
    "        added_user = set()\n",
    "        pre_start = self.current\n",
    "        pre_added_user = -1\n",
    "        pre_task_container_id = -1\n",
    "\n",
    "        user_answer_list = []\n",
    "        answered_correctly_list = []\n",
    "        while self.current < self.len:\n",
    "            crr_user_id = self.user_id[self.current]\n",
    "            crr_task_container_id = self.task_container_id[self.current]\n",
    "            crr_content_type_id = self.content_type_id[self.current]\n",
    "            if crr_content_type_id == 1:\n",
    "                # no more than one task_container_id of \"questions\" from any single user\n",
    "                # so we only care for content_type_id == 0 to break loop\n",
    "                user_answer_list.append(self.user_answer[self.current])\n",
    "                answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "                self.current += 1\n",
    "                continue\n",
    "            if crr_user_id in added_user and ((crr_user_id != pre_added_user) or (crr_task_container_id != pre_task_container_id)):\n",
    "                # known user(not prev user or differnt task container)\n",
    "                return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            if len(added_user) == self.max_user:\n",
    "                if  crr_user_id == pre_added_user and crr_task_container_id == pre_task_container_id:\n",
    "                    user_answer_list.append(self.user_answer[self.current])\n",
    "                    answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "                    self.current += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "            added_user.add(crr_user_id)\n",
    "            pre_added_user = crr_user_id\n",
    "            pre_task_container_id = crr_task_container_id\n",
    "            user_answer_list.append(self.user_answer[self.current])\n",
    "            answered_correctly_list.append(self.answered_correctly[self.current])\n",
    "            self.current += 1\n",
    "        if pre_start < self.current:\n",
    "            return self.fix_df(user_answer_list, answered_correctly_list, pre_start)\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_org = valid.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
